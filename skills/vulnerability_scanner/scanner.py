"""
Vulnerability Scanner - Detects security issues in Python code.

Scans for:
- Injection vulnerabilities (SQL, Command, Code)
- Hardcoded secrets and credentials
- Weak cryptographic implementations
- Insecure deserialization
- Path traversal issues
- Missing input validation
- Configuration security issues
"""

import re
import os
import ast
import json
from pathlib import Path
from dataclasses import dataclass, field
from typing import Optional, List, Dict, Any


@dataclass
class Vulnerability:
    """A security vulnerability found in code."""
    file_path: str
    line_number: int
    vulnerability_type: str
    severity: str  # critical, high, medium, low, info
    category: str
    code_snippet: str
    description: str
    recommendation: str


# Vulnerability patterns for static analysis
VULNERABILITY_PATTERNS = [
    # ========================================
    # INJECTION VULNERABILITIES
    # ========================================
    
    # SQL Injection
    (
        r'(?i)(execute|executemany|cursor\.execute)\s*\(\s*f?[\'"]',
        'SQL Injection Risk',
        'high',
        'injection',
        'Using string formatting in SQL queries is dangerous. Use parameterized queries instead.',
        'Replace f-strings or % formatting with parameterized queries: execute("SELECT * FROM users WHERE id = ?", (user_id,))'
    ),
    
    # Command Injection
    (
        r'(?i)(os\.system|subprocess\.(call|run|popen|getstatusoutput)|commands\.(run|popen))',
        'Command Injection Risk',
        'high',
        'injection',
        'Using shell commands with user input can lead to command injection.',
        'Use subprocess with listå½¢å¼çš„ arguments instead of shell=True or string concatenation.'
    ),
    
    # Eval with user input
    (
        r'(?i)\beval\s*\(\s*(request|user|input|params|args|data|json)',
        'Eval Injection',
        'critical',
        'injection',
        'eval() with user input allows arbitrary code execution.',
        'Never use eval() with external input. Use ast.literal_eval() for safe evaluation of literals.'
    ),
    
    # Exec with user input
    (
        r'(?i)\bexec\s*\(\s*(request|user|input|params|args|data|json)',
        'Exec Injection',
        'critical',
        'injection',
        'exec() with user input allows arbitrary code execution.',
        'Avoid exec() entirely. Refactor code to not require dynamic execution.'
    ),
    
    # Pickle deserialization (unsafe)
    (
        r'(?i)\bpickle\.loads?\s*\(',
        'Insecure Deserialization (Pickle)',
        'critical',
        'injection',
        'Pickle can execute arbitrary code during deserialization.',
        'Use safer formats like JSON, MessagePack, or Protocol Buffers.'
    ),
    
    # YAML unsafe load
    (
        r'(?i)yaml\.load\s*\(\s*(?!.*Loader)',
        'Insecure YAML Deserialization',
        'high',
        'injection',
        'yaml.load without Loader is vulnerable to arbitrary code execution.',
        'Use yaml.safe_load() or specify a safe Loader.'
    ),
    
    # ========================================
    # HARDCODED SECRETS
    # ========================================
    
    # API Keys patterns
    (
        r'(?i)(api[_-]?key|apikey)\s*=\s*[\'"][a-zA-Z0-9_\-]{8,}[\'"]',
        'Hardcoded API Key',
        'high',
        'secrets',
        'API key found in source code.',
        'Move secrets to environment variables or a secure secrets manager.'
    ),
    
    # Generic secret pattern
    (
        r'(?i)(secret|password|token|auth[_-]?key)\s*=\s*[\'"][^\'\"]{4,}[\'"]',
        'Hardcoded Secret',
        'high',
        'secrets',
        'Secret value found in source code.',
        'Use environment variables: os.environ.get("SECRET")'
    ),
    
    # AWS Access Key
    (
        r'(?i)(AKIA|ABIA|ACCA|ASIA)[A-Z0-9]{16}',
        'AWS Access Key',
        'critical',
        'secrets',
        'AWS access key found in code.',
        'Rotate immediately. Use IAM roles or AWS Secrets Manager.'
    ),
    
    # Private key file
    (
        r'-----BEGIN (RSA |EC |DSA |OPENSSH |PGP )?PRIVATE KEY-----',
        'Private Key in Code',
        'critical',
        'secrets',
        'Private key found in source code.',
        'Store keys in files with restricted permissions, use key management services.'
    ),
    
    # JWT Secret
    (
        r'(?i)(jwt[_-]?secret|secret[_-]?key)\s*[\'=:\s]+[\'"][^\'\"]{16,}[\'"]',
        'Hardcoded JWT Secret',
        'high',
        'secrets',
        'JWT signing secret found in code.',
        'Use environment variables for signing keys.'
    ),
    
    # ========================================
    # CRYPTOGRAPHIC ISSUES
    # ========================================
    
    # MD5 for passwords
    (
        r'(?i)hashlib\.md5\s*\(',
        'Weak Cryptographic Hash (MD5)',
        'high',
        'crypto',
        'MD5 is cryptographically broken and unsuitable for passwords.',
        'Use bcrypt, scrypt, or Argon2 for password hashing.'
    ),
    
    # SHA1 for passwords
    (
        r'(?i)hashlib\.sha1\s*\(',
        'Weak Cryptographic Hash (SHA1)',
        'medium',
        'crypto',
        'SHA1 is deprecated for password hashing.',
        'Use bcrypt, scrypt, or Argon2 for password hashing.'
    ),
    
    # DES/ECB mode - more specific patterns
    (
        r'(?i)DES\.new\s*\(|DES\.DES\s*\(',
        'Weak Encryption Algorithm (DES)',
        'high',
        'crypto',
        'DES is considered weak for cryptographic use.',
        'Use AES-256-GCM or ChaCha20-Poly1305 for encryption.'
    ),
    (
        r'(?i)modes\.ECBMode',
        'Weak Encryption Mode (ECB)',
        'high',
        'crypto',
        'ECB mode reveals patterns in encrypted data.',
        'Use AES-256-GCM or ChaCha20-Poly1305 for authenticated encryption.'
    ),
    (
        r'(?i)ARC4|RC4\.new',
        'Weak Encryption Algorithm (RC4)',
        'high',
        'crypto',
        'RC4 is cryptographically broken.',
        'Use AES-256-GCM or ChaCha20-Poly1305 for encryption.'
    ),
    
    # Random instead of SecureRandom
    (
        r'(?i)\brandom\.(random|randint|choice|shuffle)',
        'Insecure Random for Cryptography',
        'medium',
        'crypto',
        'random module is not cryptographically secure.',
        'Use secrets.token_bytes(), secrets.randbelow(), or os.urandom().'
    ),
    
    # ========================================
    # PATH TRAVERSAL
    # ========================================
    
    # Open with user-controlled path
    (
        r'open\s*\(\s*(request|user|input|params|args|data|json|session)[.',
        'Potential Path Traversal',
        'high',
        'path',
        'File path derived from user input.',
        'Validate and sanitize paths. Use os.path.basename() and restrict to allowed directories.'
    ),
    
    # Join path with user input
    (
        r'os\.path\.join\s*\(\s*(request|user|input|params|args|data)[.,]',
        'Path Traversal Risk',
        'high',
        'path',
        'User input used in path construction.',
        'Validate the result is within expected directory using os.path.realpath().'
    ),
    
    # File read with dangerous mode
    (
        r'\.read\s*\(\s*1024\s*\)',
        'Unbounded File Read',
        'medium',
        'path',
        'Unbounded file read could lead to memory exhaustion or path traversal.',
        'Read in chunks with size limits and validate paths.'
    ),
    
    # ========================================
    # INPUT VALIDATION
    # ========================================
    
    # Flask debug mode in production
    (
        r'(?i)app\.run\s*\([^)]*debug\s*=\s*True',
        'Debug Mode Enabled',
        'high',
        'config',
        'Running with debug=True in production exposes sensitive information.',
        'Set debug=False or use FLASK_ENV=production.'
    ),
    
    # Django debug in production
    (
        r'(?i)DEBUG\s*=\s*True',
        'Django DEBUG Enabled',
        'high',
        'config',
        'Django DEBUG mode in production exposes stack traces and settings.',
        'Set DEBUG=False in production environments.'
    ),
    
    # CORS wildcard
    (
        r'(?i)CORS.*allow.*origins.*\*',
        'Permissive CORS Configuration',
        'medium',
        'config',
        'CORS wildcard allows any origin to access resources.',
        'Restrict CORS to specific trusted origins.'
    ),
    
    # No rate limiting
    (
        r'(?i)RateLimit\s*=\s*None|\.without.*rate.?limit',
        'Missing Rate Limiting',
        'medium',
        'config',
        'Endpoint appears to have no rate limiting.',
        'Implement rate limiting for sensitive endpoints.'
    ),
    
    # ========================================
    # INSECURE DEFAULTS
    # ========================================
    
    # Temporary file without secure mode
    (
        r'(?i)tempfile\.(mktemp|TemporaryFile)',
        'Insecure Temporary File',
        'medium',
        'crypto',
        'mktemp() creates predictable temporary files.',
        'Use tempfile.NamedTemporaryFile with mode=... and delete=True.'
    ),
    
    # SSL verification disabled
    (
        r'(?i)(verify=False|disable_warnings|ssl._create_unverified_context)',
        'SSL Verification Disabled',
        'high',
        'crypto',
        'SSL certificate verification is disabled.',
        'Always verify SSL certificates in production.'
    ),
    
    # Print statements in production
    (
        r'\bprint\s*\(\s*(request|session|user|password|token|secret|key|auth)',
        'Sensitive Data in Logs',
        'low',
        'secrets',
        'Potential sensitive data being logged.',
        'Use logging module with appropriate filters. Avoid logging PII.'
    ),
]


class VulnerabilityScanner:
    """Scanner for detecting security vulnerabilities in Python code."""
    
    def __init__(self, base_path: str = "."):
        self.base_path = Path(base_path)
        self.findings: List[Vulnerability] = []
        self.files_scanned = 0
        self.lines_scanned = 0
    
    def scan_file(self, file_path: Path) -> List[Vulnerability]:
        """Scan a single Python file for vulnerabilities."""
        findings = []
        
        if not file_path.exists():
            return findings
        
        if file_path.suffix != '.py':
            return findings
        
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()
                content = ''.join(lines)
                self.files_scanned += 1
                self.lines_scanned += len(lines)
                
                # Pattern-based scanning
                findings.extend(self._scan_patterns(file_path, content, lines))
                
                # AST-based scanning for deeper analysis
                findings.extend(self._scan_ast(file_path, content, lines))
                
        except (IOError, UnicodeDecodeError) as e:
            print(f"Warning: Could not scan {file_path}: {e}")
        
        return findings
    
    def _scan_patterns(self, file_path: Path, content: str, lines: List[str]) -> List[Vulnerability]:
        """Scan using regex patterns."""
        findings = []
        
        for pattern_info in VULNERABILITY_PATTERNS:
            if len(pattern_info) == 6:
                pattern, vuln_type, severity, category, description, recommendation = pattern_info
            else:
                continue
            
            try:
                matches = re.finditer(pattern, content)
                for match in matches:
                    # Find line number
                    line_num = content[:match.start()].count('\n') + 1
                    
                    # Get surrounding code
                    line = lines[min(line_num - 1, len(lines) - 1)].strip()
                    
                    findings.append(Vulnerability(
                        file_path=str(file_path),
                        line_number=line_num,
                        vulnerability_type=vuln_type,
                        severity=severity,
                        category=category,
                        code_snippet=line[:100],
                        description=description,
                        recommendation=recommendation
                    ))
            except re.error:
                continue
        
        return findings
    
    def _scan_ast(self, file_path: Path, content: str, lines: List[str]) -> List[Vulnerability]:
        """Scan using AST analysis for deeper vulnerability detection."""
        findings = []
        
        try:
            tree = ast.parse(content)
        except SyntaxError:
            return findings
        
        for node in ast.walk(tree):
            # Check for dangerous function calls
            if isinstance(node, ast.Call):
                func_name = None
                
                if isinstance(node.func, ast.Name):
                    func_name = node.func.id
                elif isinstance(node.func, ast.Attribute):
                    func_name = node.func.attr
                
                if func_name in ['eval', 'exec']:
                    # Check if arguments contain untrusted sources
                    for arg in node.args:
                        if isinstance(arg, ast.Subscript):
                            findings.append(Vulnerability(
                                file_path=str(file_path),
                                line_number=node.lineno,
                                vulnerability_type=f"Dangerous {func_name}() Usage",
                                severity='critical' if func_name == 'eval' else 'high',
                                category='injection',
                                code_snippet=lines[node.lineno - 1].strip()[:100],
                                description=f'{func_name}() can execute arbitrary code.',
                                recommendation=f'Avoid {func_name}(). Use ast.literal_eval() or refactor.'
                            ))
        
        return findings
    
    def scan_directory(self, directory: Path = None) -> Dict[str, Any]:
        """Scan a directory recursively for vulnerabilities."""
        if directory is None:
            directory = self.base_path
        
        self.findings = []
        
        for file_path in directory.rglob('*.py'):
            # Skip common non-vulnerable directories
            if any(part in str(file_path) for part in ['.git', '__pycache__', '.venv', 'node_modules', 'tests/fixtures']):
                continue
            
            self.findings.extend(self.scan_file(file_path))
        
        return self.generate_report()
    
    def generate_report(self) -> Dict[str, Any]:
        """Generate a summary report of findings."""
        # Count by severity
        severity_counts = {
            'critical': 0,
            'high': 0,
            'medium': 0,
            'low': 0,
            'info': 0
        }
        
        # Count by category
        category_counts = {}
        
        for finding in self.findings:
            severity_counts[finding.severity] = severity_counts.get(finding.severity, 0) + 1
            category_counts[finding.category] = category_counts.get(finding.category, 0) + 1
        
        return {
            'files_scanned': self.files_scanned,
            'lines_scanned': self.lines_scanned,
            'total_findings': len(self.findings),
            'severity_counts': severity_counts,
            'category_counts': category_counts,
            'findings': [f.__dict__ for f in self.findings],
            'summary': self._generate_summary(severity_counts, category_counts)
        }
    
    def _generate_summary(self, severity_counts: Dict, category_counts: Dict) -> str:
        """Generate a human-readable summary."""
        total = len(self.findings)
        
        if total == 0:
            return "âœ… No vulnerabilities detected!"
        
        critical = severity_counts.get('critical', 0)
        high = severity_counts.get('high', 0)
        
        if critical > 0 or high > 0:
            risk_level = "ðŸš¨ HIGH RISK"
        elif total > 10:
            risk_level = "âš ï¸  MODERATE RISK"
        else:
            risk_level = "âœ… LOW RISK"
        
        return f"{risk_level}: {total} issues found ({critical} critical, {high} high)"
    
    def print_report(self, json_output: bool = False):
        """Print a human-readable security report."""
        if json_output:
            print(json.dumps(self.findings, indent=2))
            return
        
        report = self.scan_directory()
        
        print("\n" + "=" * 70)
        print("ðŸ”’ CLAWGOTCHI VULNERABILITY SCANNER")
        print("=" * 70)
        
        print(f"\nðŸ“ Scanned: {report['files_scanned']} files, {report['lines_scanned']} lines")
        print(f"ðŸ“Š {report['summary']}")
        
        print(f"\n{'=' * 70}")
        print("âš ï¸  SEVERITY BREAKDOWN")
        print(f"{'=' * 70}")
        print(f"   ðŸ”´ Critical: {report['severity_counts'].get('critical', 0)}")
        print(f"   ðŸŸ  High:     {report['severity_counts'].get('high', 0)}")
        print(f"   ðŸŸ¡ Medium:   {report['severity_counts'].get('medium', 0)}")
        print(f"   ðŸ”µ Low:      {report['severity_counts'].get('low', 0)}")
        print(f"   âšª Info:     {report['severity_counts'].get('info', 0)}")
        
        if not report['findings']:
            print("\nâœ… No security vulnerabilities detected!")
            print("\nRemember to:")
            print("  â€¢ Keep dependencies updated")
            print("  â€¢ Use environment variables for secrets")
            print("  â€¢ Follow OWASP guidelines")
            return
        
        print(f"\n{'=' * 70}")
        print("ðŸ” DETAILED FINDINGS (sorted by severity)")
        print(f"{'=' * 70}")
        
        # Sort findings by severity
        severity_order = {'critical': 0, 'high': 1, 'medium': 2, 'low': 3, 'info': 4}
        sorted_findings = sorted(
            report['findings'],
            key=lambda x: (severity_order.get(x['severity'], 5), x['file_path'], x['line_number'])
        )
        
        # Display findings
        current_severity = None
        for finding in sorted_findings[:50]:  # Limit output
            if finding['severity'] != current_severity:
                current_severity = finding['severity']
                severity_icons = {
                    'critical': 'ðŸ”´',
                    'high': 'ðŸŸ ',
                    'medium': 'ðŸŸ¡',
                    'low': 'ðŸ”µ',
                    'info': 'âšª'
                }
                print(f"\n### {severity_icons.get(current_severity, 'âšª')} {current_severity.upper()} SEVERITY ###\n")
            
            print(f"ðŸ“ {finding['file_path']}:{finding['line_number']}")
            print(f"   Type: {finding['vulnerability_type']}")
            print(f"   Code: {finding['code_snippet'][:80]}")
            print(f"   Fix:  {finding['recommendation'][:60]}...")
            print()
        
        if len(sorted_findings) > 50:
            print(f"... and {len(sorted_findings) - 50} more findings")
        
        print(f"\n{'=' * 70}")
        print("ðŸ’¡ RECOMMENDATIONS")
        print(f"{'=' * 70}")
        print("""
1. Address critical and high severity issues immediately
2. Use environment variables for all secrets and API keys
3. Prefer parameterized queries over string formatting
4. Keep dependencies updated and monitor CVE databases
5. Implement proper input validation on all user-facing endpoints
6. Use secure configurations for all frameworks in production
        """)


# CLI interface
if __name__ == "__main__":
    import sys
    
    # Default to current directory
    base_path = sys.argv[1] if len(sys.argv) > 1 else "."
    json_output = '--json' in sys.argv
    
    scanner = VulnerabilityScanner(base_path)
    scanner.print_report(json_output=json_output)
